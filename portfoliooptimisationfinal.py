# -*- coding: utf-8 -*-
"""PortfolioOptimisationFinal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/182cdkEnuvKYh0uqx1rHE9gs84woxeEKj

**Part 1**

---

Import all relevant libraries
"""

import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as sp
from pandas_datareader import data
import pandas as pd
import statsmodels.api as sm
import statsmodels.formula.api as smf
from bokeh.io import output_notebook, show
from bokeh.plotting import figure
from scipy.optimize import fsolve
import yfinance as yf

"""Downloading Ticker names and corresponding data."""

table = pd.read_html('https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average')[1]
tickers = table['Symbol'].tolist()

data = yf.download(tickers,start='2010-01-03')['Adj Close']

data.head()

"""Extracting Dates"""

Dates = pd.to_datetime(data.index, format='%Y-%m-%d')
Dates

"""Visualising the closing prices of the stocks in the index."""

plt.figure(figsize=(20, 20))

plt.subplots_adjust(left=0.1,
                    bottom=0.1,
                    right=0.9,
                    top=0.9,
                    wspace=0.2,
                    hspace=0.4)

for i in range(len(tickers)):
    plt.subplot(6,5,i+1)
    plt.grid()
    plt.plot(Dates,data.iloc[:,i], label = data.columns[i])
    plt.legend()
    plt.xticks(rotation=70)
plt.show()

"""
Vector time is found using shape function.
Brownian motion is  indicated by simple returns and it is mentioned as dfbrown and random walk behaviour is observed with zero drift.
Other stats are as follows:"""

from datetime import date

d0 = Dates[0]
d1 = Dates[data.shape[0]-1]
delta = d1 - d0
T = delta.days/365.25
T

sampling_points = data.shape[0]-1
dt = T/sampling_points
time = np.linspace(0,T,sampling_points+1)
time

len(time)/T

len(time)

simplereturns = data.pct_change(1)
simplereturns.iloc[0] = 0
simplereturns.fillna(0)

"""The volatility is observed outside the trading period (i.e., prior to 2010)"""

dj_vol = yf.download(tickers,start='2005-02-02', end='2010-01-01')['Adj Close']

dow = yf.download('DOW', start = '2019-03-20', end = '2022-12-31')['Adj Close']

dj_dates =  pd.to_datetime(dj_vol.index, format='%Y-%m-%d')
dowdates = pd.to_datetime(dow.index, format='%Y-%m-%d')

simpleretdow = dow.pct_change(1)
simpleretdow = simpleretdow.fillna(0)
simpleretdow

simpleretvol = dj_vol.pct_change(1)
simpleretvol = simpleretvol.fillna(0)
simpleretvol

sigmaQvol = simpleretvol.std()*np.sqrt(252)
sigmaQvol

sigmaQdow = simpleretdow.std()*np.sqrt(252)
sigmaQdow

sigmaQvol['DOW'] = sigmaQdow
sigmaQvol

simplereturns = data.pct_change(1)
simplereturns = simplereturns.fillna(0)
simplereturns
dfbrown = simplereturns.cumsum()
dfbrown

# dfbrownvol = simpleretvol.cumsum()
# dfbrownvol

"""The following hypothesis is tested: H0: mu = 0 vs H1: mu > 0.
The choice of parameter mu determines whether it is possible to capitalize the drift.
"""

plt.figure(figsize=(20, 20))
# plt.plot(Dates,sp.norm.ppf(0.95)*sigmaQ10y*np.sqrt(time), label = "95 confidence")
# plt.plot(Dates,sp.norm.ppf(0.99)*sigmaQ10y*np.sqrt(time), label = "99 confidence")
plt.subplots_adjust(left=0.01,
                    bottom=0.01,
                    right=0.99,
                    top=0.99,
                    wspace=0.2,
                    hspace=0.4)

for i in range(len(tickers)):
  if data.columns[i] == 'DOW':
    length = len(data.loc['20-03-2019':])
    datadow = data['DOW'].tail(length)
    dowdates = data.index[-length:]
    timedow = time[-length:]
    plt.subplot(6,5,i+1)
    plt.grid()
    plt.plot(dowdates,datadow, label = "DOW")
    plt.plot(dowdates,sp.norm.ppf(0.95)*sigmaQvol[i]*np.sqrt(timedow), label = "95 confidence")
    plt.plot(dowdates,sp.norm.ppf(0.99)*sigmaQvol[i]*np.sqrt(timedow), label = "99 confidence")
    plt.legend()
    plt.xticks(rotation=70)
  else:
    plt.subplot(6,5,i+1)
    plt.grid()
    plt.plot(Dates,data.iloc[:,i], label = data.columns[i])
    plt.plot(Dates,sp.norm.ppf(0.95)*sigmaQvol[i]*np.sqrt(time), label = "95 confidence")
    plt.plot(Dates,sp.norm.ppf(0.99)*sigmaQvol[i]*np.sqrt(time), label = "99 confidence")
    plt.legend()
    plt.xticks(rotation=70)
plt.show()

history = pd.DataFrame(columns = tickers)
hisdates = dj_dates
djhist = dj_vol

# for ticker in djhist:
#   if ticker == "DOW":
#      x = yf.Ticker(ticker)
#      est = x.history(start='2019-01-01', end = '2023-01-01')['Close']
#   elif ticker == "V":
#       x = yf.Ticker(ticker)
#       est = x.history(start='2008-01-01', end = '2010-01-01')['Close']
#   else:
#     x = yf.Ticker(ticker)
#     est = x.history(start='2005-01-01', end = '2010-01-01')['Close']
#   history[ticker] = est
# history.index = est.index.date
for ticker in djhist:
  x = yf.Ticker(ticker)
  est = x.history(start='2005-01-01', end = '2010-01-01')['Close']
  history[ticker] = est
history.index = est.index.date

history = history.fillna(0)
history

for ticker in djhist:
  if ticker == "DOW":
    x = yf.Ticker(ticker)
    est = x.history(start='2019-01-01', end = '2023-01-01')['Close']
    estreturnsdow = est.pct_change(1)
    estbrowndow = estreturnsdow.cumsum()
    mudow = estbrowndow/4
  elif ticker == "V":
    x = yf.Ticker(ticker)
    est = x.history(start='2008-01-01', end = '2010-01-01')['Close']
    estreturnsv = est.pct_change(1)
    estbrownv = estreturnsv.cumsum()
    mu = estbrownv/2

"""For estimation, I am using Adj_Closed values so that dividend is included in the calculation."""

estimation = history

estreturns = estimation.pct_change(1)
# estreturns = estreturns.fillna(0)
estbrown = estreturns.cumsum()
estbrown.tail()
# estreturns.tail()

estreturns

estbrown = estbrown.iloc[-1]/5

#the drift is rejected as the ex post is too small.
mu = estbrown.round(3)
mu['DOW'] = mudow
mu['V'] = muv

"""Mu is calculated from estimated brown which is once again, basically from the history part and in this example, that would be before February 2nd, 2011."""

plt.figure(figsize=(20, 20))

plt.subplots_adjust(left=0.01,
                    bottom=0.01,
                    right=0.99,
                    top=0.99,
                    wspace=0.2,
                    hspace=0.4)

for i in range(len(tickers)):
  print(mu[i])
  # if data.columns[i] == 'DOW':
  #   length = len(data.loc['20-03-2019':])
  #   datadow = dfbrown['DOW'].tail(length)
  #   dowdates = data.index[-length:]
  #   timedow = time[-length:]
  #   plt.subplot(6,5,i+1)
  #   plt.grid()
  #   plt.plot(dowdates,timedow*mu[i], label = "Expectation")
  #   plt.plot(dowdates,datadow, label = dfbrown.columns[i])
  #   plt.plot(dowdates,sp.norm.ppf(0.95)*sigmaQvol[i]*np.sqrt(timedow), label = "95 confidence")
  #   plt.legend()
  #   plt.xticks(rotation=70)
  # else:
  #   plt.subplot(6,5,i+1)
  #   plt.grid()
  #   plt.plot(Dates,time*mu[i], label = "Expectation")
  #   plt.plot(Dates,dfbrown.iloc[:,i], label = dfbrown.columns[i])
  #   plt.plot(Dates,time*mu[i] + sp.norm.ppf(0.95)*sigmaQvol[i]*np.sqrt(time), label = "95 confidence")
  #   plt.legend()
  #   plt.xticks(rotation=70)
# plt.show()

def merton(X,mu,sigmaQ,t):
    x = sp.norm.pdf(X,mu*t, sigmaQ*np.sqrt(t))/sp.norm.pdf(X,0,sigmaQ*np.sqrt(t))
    return x

Merton = pd.DataFrame()

Merton = pd.DataFrame(index=dfbrown.index, columns=dfbrown.columns)
Merton.iloc[0]=1
Merton

for ticker in dfbrown.columns:
    xbrown = dfbrown[ticker]
    x_mu = mu[ticker]
    x_sigmaQ = sigmaQvol[ticker]

    # for i in range(1, len(time)):
    #     Merton.loc[time[i], ticker] = merton(xbrown[i], x_mu, x_sigmaQ, time[i])
    for i in dfbrown.index[1:]:
      ind = Merton.index.get_loc(pd.to_datetime(i))
      Merton.loc[i, ticker] = merton(xbrown[i], x_mu, x_sigmaQ, time[ind])
# Ensure the Merton DataFrame has the correct dimensions
print(Merton.shape)

Merton = Merton.fillna(0)
Merton

Normalized_Asset_Price = pd.DataFrame(index=Merton.index, columns=Merton.columns)
Normalized_Asset_Price.info

# Normalized_Asset_Price = pd.DataFrame(index=Merton.index, columns=Merton.columns)
for ticker in Merton.columns:
    for date in Merton.index:
        Normalized_Asset_Price.loc[date, ticker] = data.loc[date, ticker] / data.loc[Merton.index[0], ticker]

Normalized_Asset_Price = Normalized_Asset_Price.fillna(0)
Normalized_Asset_Price

plt.figure(figsize=(20, 20))

plt.subplots_adjust(left=0.01,
                    bottom=0.01,
                    right=0.99,
                    top=0.99,
                    wspace=0.2,
                    hspace=0.4)

for i in range(len(tickers)):
  plt.subplot(6,5,i+1)
  plt.grid()
  plt.plot(Dates, data.iloc[:,i], label = data.columns[i])
  plt.plot(Dates, Merton.iloc[:,i], label = "Merton")
  plt.legend()
  plt.xticks(rotation=70)
plt.show()

Log_Returns = Merton.apply(lambda x: np.log(x.iloc[-1]))
Log_Returns

Replication = pd.DataFrame(index = Merton.index, columns = Merton.columns)

Replication.iloc[0] = 1

Replication

for ticker in Merton.columns:
    for i, row in Merton.iterrows():
        ind = Merton.index.get_loc(i)
        next_index = Merton.index[ind + 1] if ind + 1 < len(Merton.index) else None

        if next_index is not None:
            Replication.loc[next_index, ticker] = Replication.loc[i, ticker] + (mu[ticker] / sigmaQvol[ticker]**2) * Replication.loc[i, ticker] * simplereturns[ticker].iloc[ind + 1]

Replication = Replication.fillna(0)
Replication

plt.figure(figsize=(20, 20))

plt.subplots_adjust(left=0.01,
                    bottom=0.01,
                    right=0.99,
                    top=0.99,
                    wspace=0.2,
                    hspace=0.4)

for i in range(len(tickers)):
  plt.subplot(6,5,i+1)
  plt.grid()
  plt.plot(Dates, Replication.iloc[:,i], label = Replication.columns[i] + "Replication")
  plt.plot(Dates, Merton.iloc[:,i], label = "Merton")
  plt.legend()
  plt.xticks(rotation=70)
plt.show()

def w(mu,sigma,t):
    return (np.exp((mu**2*t)/sigma**2) - np.exp((mu*(mu + sigma**2)*t)/sigma**2))/(2*np.exp((mu**2*t)/sigma**2) - np.exp((mu*(mu + sigma**2)*t)/sigma**2) - np.exp((-mu + mu**2/sigma**2 + sigma**2)*t))

Markowitz = pd.DataFrame(columns = Merton.columns, index = Merton.index)
for ticker in Merton.columns:
  Markowitz[ticker] = Normalized_Asset_Price[ticker]*w(mu[ticker],sigmaQvol[ticker],T) + (1 - w(mu[ticker],sigmaQvol[ticker],T))

Markowitz

Merton

Normalized_Asset_Price

plt.figure(figsize=(20, 20))

plt.subplots_adjust(left=0.01,
                    bottom=0.01,
                    right=0.99,
                    top=0.99,
                    wspace=0.2,
                    hspace=0.4)

for i in range(len(tickers)):
  plt.subplot(6,5,i+1)
  plt.grid()
  plt.plot(Dates, data.iloc[:,i], label = Replication.columns[i] + " Replication")
  plt.plot(Dates, Merton.iloc[:,i], label = "Merton")
  plt.plot(Dates, Markowitz.iloc[:,i], label = "Markowitz")
  plt.legend()
  plt.xticks(rotation=70)
plt.show()

def sharpe(prices):
    returns = prices.pct_change(1)
    mu = np.mean(returns)*252
    sigma = np.std(returns)*np.sqrt(252)
    return mu/sigma

sharpe(data)

sharpe(Merton)

sharpe(Markowitz)

def max_drawdown(prices):
    a = np.maximum.accumulate(prices)
    return np.max(1 - prices/a)

asset_max_drawdowndf = pd.DataFrame(columns = Merton.columns, index = Merton.index)
for ticker in Merton.columns:
  asset_max_drawdowndf[ticker] = max_drawdown(data[ticker])
asset_max_drawdowndf = asset_max_drawdowndf.fillna(0)
asset_max_drawdowndf

merton_max_drawdowndf = pd.DataFrame(columns = Merton.columns, index = Merton.index)
for ticker in Merton.columns:
  merton_max_drawdowndf[ticker] = max_drawdown(Merton[ticker])
merton_max_drawdowndf

markowitz_max_drawdowndf = pd.DataFrame(columns = Merton.columns, index = Merton.index)
for ticker in Merton.columns:
  markowitz_max_drawdowndf[ticker] = max_drawdown(Markowitz[ticker])
markowitz_max_drawdowndf

def mean(prices):
    returns = prices.pct_change(1)
    mu = np.mean(returns)*252
    return mu

mean(Normalized_Asset_Price)

MertonM10df = pd.DataFrame(columns = Merton.columns, index = Merton.index)
MertonM1df = pd.DataFrame(columns = Merton.columns, index = Merton.index)
MertonM14df = pd.DataFrame(columns = Merton.columns, index = Merton.index)
MertonM30df = pd.DataFrame(columns = Merton.columns, index = Merton.index)
MertonM40df = pd.DataFrame(columns = Merton.columns, index = Merton.index)

MertonM10 = np.empty(len(time))
MertonM10[0]=1
for ticker in Merton.columns:
  xbrown = dfbrown[ticker]
  for i in range(1,len(time)):
      MertonM10[i] = merton(xbrown[i],-0.1,sigmaQvol[ticker],time[i])
  MertonM10df[ticker] = MertonM10


MertonM1 = np.empty(len(time))
MertonM1[0]=1
for ticker in Merton.columns:
  xbrown = dfbrown[ticker]
  for i in range(1,len(time)):
      MertonM1[i] = merton(xbrown[i],-0.01,sigmaQvol[ticker],time[i])
  MertonM1df[ticker] = MertonM1

MertonM14 = np.empty(len(time))
MertonM14[0]=1
for ticker in Merton.columns:
  xbrown = dfbrown[ticker]
  for i in range(1,len(time)):
      MertonM14[i] = merton(xbrown[i],0.14,sigmaQvol[ticker],time[i])
  MertonM14df[ticker] = MertonM14

MertonM30 = np.empty(len(time))
MertonM30[0]=1
for ticker in Merton.columns:
  xbrown = dfbrown[ticker]
  for i in range(1,len(time)):
      MertonM30[i] = merton(xbrown[i],0.3,sigmaQvol[ticker],time[i])
  MertonM30df[ticker] = MertonM30

MertonM40 = np.empty(len(time))
MertonM40[0]=1
for ticker in Merton.columns:
  xbrown = dfbrown[ticker]
  for i in range(1,len(time)):
      MertonM40[i] = merton(xbrown[i],0.4,sigmaQvol[ticker],time[i])
  MertonM40df[ticker] = MertonM40

MertonM10df_logR = MertonM10df.applymap(lambda x: np.log(x) if pd.notna(x) else np.nan)
MertonM1df_logR = MertonM1df.applymap(lambda x: np.log(x) if pd.notna(x) else np.nan)
MertonM14df_logR = MertonM14df.applymap(lambda x: np.log(x) if pd.notna(x) else np.nan)
MertonM30df_logR = MertonM30df.applymap(lambda x: np.log(x) if pd.notna(x) else np.nan)
MertonM40df_logR = MertonM40df.applymap(lambda x: np.log(x) if pd.notna(x) else np.nan)

Merton_logR = Merton.applymap(lambda x: np.log(x) if pd.notna(x) else np.nan)

plt.figure(figsize=(20, 20))

plt.subplots_adjust(left=0.01,
                    bottom=0.01,
                    right=0.99,
                    top=0.99,
                    wspace=0.2,
                    hspace=0.4)

for i in range(len(tickers)):
  plt.subplot(6,5,i+1)
  plt.grid()
  plt.plot(Dates, MertonM10df_logR.iloc[:,i], label = Merton.columns[i] + " M10")
  plt.plot(Dates, MertonM1df_logR.iloc[:,i], label = "M1")
  plt.plot(Dates, MertonM14df_logR.iloc[:,i], label = "M14")
  plt.plot(Dates, MertonM30df_logR.iloc[:,i], label = "M30")
  plt.plot(Dates, MertonM40df_logR.iloc[:,i], label = "M40")
  plt.legend()
  plt.xticks(rotation=70)
plt.show()

def merton_bayes(sigma, mu0, s0, stock0, simple_return, time):
    return stock0*np.exp((s0**2*simple_return**2  + 2*mu0*simple_return*sigma**2 - mu0**2*sigma**2*time)/(2*sigma**2*(sigma**2+s0**2*time)))/(np.sqrt(1+s0**2/sigma**2*time))

mu0 = -0.01
sigma0 = 0.08

plt.figure(figsize=(20, 20))

plt.subplots_adjust(left=0.01,
                    bottom=0.01,
                    right=0.99,
                    top=0.99,
                    wspace=0.2,
                    hspace=0.4)

for i in range(len(tickers)):
  plt.subplot(6,5,i+1)
  plt.grid()
  plt.plot(Dates, Merton_logR.iloc[:,i], label = Merton.columns[i] + " Merton")
  plt.plot(Dates, MertonM1df_logR.iloc[:,i], label = "M1")
  plt.plot(Dates, MertonM14df_logR.iloc[:,i], label = "M14")
  plt.legend()
  plt.xticks(rotation=70)
plt.show()

mu0 = 0.06
sigma0 = 0.08

def posteriormean(m0,sigma0,sigma,x,time):
    return (m0/sigma0**2 + x/sigma**2)/(1/sigma0**2+time/sigma**2)

Bayes = pd.DataFrame(columns=Merton.columns, index=Merton.index)
Bayes.iloc[0] = 1

for ticker in Merton.columns:
   if ticker == 'DOW':
    continue
   for i, row in Merton.iterrows():
        ind = Merton.index.get_loc(i)
        next_index = Merton.index[ind + 1] if ind + 1 < len(Merton.index) else None
        # print(time[ind])
        if next_index is not None:
          Bayes.loc[next_index, ticker] = (Bayes.loc[i, ticker]+
           (posteriormean(mu0, sigma0, sigmaQvol[ticker], dfbrown.loc[i, ticker], time[ind]) / sigmaQvol[ticker]**2)*
            (simplereturns[ticker].iloc[ind + 1])* Bayes.loc[i, ticker])

mu0 = 0.04
sigma0 = 0.01

merton_bayes_41 = pd.DataFrame(columns = Merton.columns, index = Merton.index)
for ticker in Merton.columns:
  if ticker == 'DOW':
    continue
  for i in range(len(tickers)):
    merton_bayes_41[ticker] = merton_bayes(sigmaQvol[ticker],mu0,sigma0,1,dfbrown[ticker],time[i])

mu0 = 0.06
sigma0 = 0.08

merton_bayes_68 = pd.DataFrame(columns = Merton.columns, index = Merton.index)
for ticker in Merton.columns:
  if ticker == 'DOW':
    continue
  for i in range(len(tickers)):
    merton_bayes_68[ticker] = merton_bayes(sigmaQvol[ticker],mu0,sigma0,1,dfbrown[ticker],time[i])

merton_bayes_68_log = merton_bayes_68.applymap(lambda x: np.log(x) if pd.notna(x) else np.nan)

merton_bayes_41_log = merton_bayes_41.applymap(lambda x: np.log(x) if pd.notna(x) else np.nan)

plt.figure(figsize=(20, 20))

plt.subplots_adjust(left=0.01,
                    bottom=0.01,
                    right=0.99,
                    top=0.99,
                    wspace=0.2,
                    hspace=0.4)

for i in range(len(tickers)):
  plt.subplot(6,5,i+1)
  plt.grid()
  plt.plot(Dates, Merton_logR.iloc[:,i], label = Merton.columns[i] + " Merton")
  plt.plot(Dates, merton_bayes_68_log.iloc[:,i], label = "MertonBayes68")
  plt.legend()
  plt.xticks(rotation=70)
plt.show()

plt.figure(figsize=(20, 20))

plt.subplots_adjust(left=0.01,
                    bottom=0.01,
                    right=0.99,
                    top=0.99,
                    wspace=0.2,
                    hspace=0.4)

for i in range(len(tickers)):
    plt.subplot(6,5,i+1)
    plt.grid()
    plt.plot(Dates, merton_bayes_68_log.iloc[:,i], label = Merton.columns[i])
    plt.plot(Dates, Bayes.iloc[:,i], label = "Bayes Replication")
    plt.legend()
    plt.xticks(rotation=70)
plt.show()

# merton_bayes = pd.DataFrame(columns = Merton.columns, index = Merton.index)
merton_bayes_sharpe = pd.DataFrame(columns = Merton.columns, index = Merton.index)
for ticker in Merton.columns:
  if ticker == 'DOW':
    continue
  for i in range(len(tickers)):
    merton_bayes_sharpe[ticker] = sharpe(merton_bayes(sigmaQvol[ticker],mu0,sigma0,1,dfbrown[ticker],time[i]))

merton_bayes_sharpe = merton_bayes_sharpe.fillna(0)
merton_bayes_sharpe

merton_bayes_maxdrawdown = pd.DataFrame(columns = Merton.columns, index = Merton.index)
for ticker in Merton.columns:
  if ticker == 'DOW':
    continue
  for i in range(len(tickers)):
    merton_bayes_maxdrawdown[ticker] = max_drawdown(merton_bayes(sigmaQvol[ticker],mu0,sigma0,1,dfbrown[ticker],time[i]))

merton_bayes_maxdrawdown = merton_bayes_maxdrawdown.fillna(0)
merton_bayes_maxdrawdown

plt.figure(figsize=(20, 20))

plt.subplots_adjust(left=0.01,
                    bottom=0.01,
                    right=0.99,
                    top=0.99,
                    wspace=0.2,
                    hspace=0.4)

for i in range(len(tickers)):
    plt.subplot(6,5,i+1)
    plt.grid()
    plt.plot(Dates, merton_bayes_68.iloc[:,i], label = merton_bayes_68.columns[i] + " Bayes 6 8")
    plt.plot(Dates, merton_bayes_41.iloc[:,i], label = "Bayes 4 1")
    plt.legend()
    plt.xticks(rotation=70)
plt.show()

"""Part 2"""

import requests
from xml.etree import ElementTree

# Loading the FX rates from ECB

def fetch_ecb_rates():
    # ECB FX rates API URL for historical data
    url = "https://www.ecb.europa.eu/stats/eurofxref/eurofxref-hist.xml"

    # Fetching the data
    response = requests.get(url)
    if response.status_code != 200:
        raise Exception("Error fetching data from ECB API")

    # Parsing XML
    tree = ElementTree.fromstring(response.content)

    # Extracting data
    all_data = []
    for cube_date in tree.findall(".//{http://www.ecb.int/vocabulary/2002-08-01/eurofxref}Cube[@time]"):
        date = cube_date.get('time')
        for cube_currency in cube_date.findall(".//{http://www.ecb.int/vocabulary/2002-08-01/eurofxref}Cube[@currency]"):
            currency = cube_currency.get('currency')
            rate = cube_currency.get('rate')
            all_data.append({'date': date, 'currency': currency, 'rate': float(rate)})

    # Creating the DataFrame and sorting by date and currency
    df = pd.DataFrame(all_data)
    df = df.sort_values(by=['date', 'currency'], ascending=[True, True]).reset_index(drop=True)

    return df

# Fetch ECB rates and save into a DataFrame
#df_rates = fetch_ecb_rates()

# Pivot the DataFrame
df1 = fetch_ecb_rates().pivot(index='date', columns='currency', values='rate')

df1 = df1.dropna(axis='columns')
df1.head()

Dates = pd.to_datetime(df1.index, format='%Y-%m-%d')

from datetime import date

d0 = Dates[0]
d1 = Dates[df1.shape[0]-1]
delta = d1 - d0
T = delta.days/365.25
T

len(Dates)/T

sampling_points = df1.shape[0]-1
dt = T/sampling_points
time = np.linspace(0,T,sampling_points+1)

plt.figure()
plt.grid()
plt.plot(Dates,df1['USD'], label = "EUR/USD")
plt.legend()
plt.show()

def reciprocal(x):
    return 1/x

df2 = df1.apply(reciprocal)

df2.head()

plt.figure()
plt.grid()
plt.plot(Dates,df2['USD'], label = "USD/EUR")
plt.legend()
plt.show()

import matplotlib.gridspec as gridspec

fig = plt.figure(figsize=(16, 10))
gs = gridspec.GridSpec(5, 8)

fig.subplots_adjust(top=0.85, bottom=0.15, left=0.2, hspace=0.8)

fig.patch.set_linewidth(5)
fig.patch.set_edgecolor('black')

for i in range(0,3):
    ax = plt.subplot(gs[0, 2 * i +1:2 * i + 3])
    plt.grid()
    plt.plot(Dates,df2.iloc[:,i], label = df2.columns[i])
    plt.legend()

for i in range(3, 7):
    ax = plt.subplot(gs[1, 2 * i - 6:2 * i + 2 - 6])
    plt.grid()
    plt.plot(Dates,df2.iloc[:,i], label = df2.columns[i])
    plt.legend()

for i in range(7, 10):
    ax = plt.subplot(gs[2, 2 * i - 13:2 * i + 2 - 13])
    plt.grid()
    plt.plot(Dates,df2.iloc[:,i], label = df2.columns[i])
    plt.legend()

for i in range(10, 14):
    ax = plt.subplot(gs[3, 2 * i - 20:2 * i + 2 - 20])
    plt.grid()
    plt.plot(Dates,df2.iloc[:,i], label = df2.columns[i])
    plt.legend()

for i in range(14, 17):
    ax = plt.subplot(gs[4, 2 * i - 27:2 * i + 2 - 27])
    plt.grid()
    plt.plot(Dates,df2.iloc[:,i], label = df2.columns[i])
    plt.legend()

plt.tight_layout()
plt.show()

# the following function is created to get the log return

logreturns = df2.apply(np.log).diff()
logreturns.iloc[0] = 0
logreturns.head()

dflog = logreturns.cumsum()

simplereturns = df2.pct_change(1)

simplereturns.iloc[0] = 0

simplereturns.head()

dfbrown = simplereturns.cumsum()

dfbrown

covmatrix = simplereturns.cov()*256.25
covmatrix

sigmaQ = np.sqrt(np.diag(covmatrix))

def quantile(sigma,t):
    return 1.96*sigma*np.sqrt(t)

def medium(sigma,t):
    return 0.675*sigma*np.sqrt(t)

fig = plt.figure(figsize=(16, 10))
gs = gridspec.GridSpec(5, 8)

fig.subplots_adjust(top=0.85, bottom=0.15, left=0.2, hspace=0.8)

fig.patch.set_linewidth(5)
fig.patch.set_edgecolor('black')

for i in range(0,3):
    ax = plt.subplot(gs[0, 2 * i +1:2 * i + 3])
    plt.grid()
    plt.plot(Dates,dflog.iloc[:,i], label = df2.columns[i])
    plt.ylim(-3*sigmaQ[i]*np.sqrt(T),3*sigmaQ[i]*np.sqrt(T))
    plt.plot(Dates,quantile(sigmaQ[i],time),color='black')
    plt.plot(Dates,quantile(-sigmaQ[i],time),color='black')
    plt.plot(Dates,medium(sigmaQ[i],time),color='red')
    plt.plot(Dates,medium(-sigmaQ[i],time),color='red')
    plt.legend()

for i in range(3, 7):
    ax = plt.subplot(gs[1, 2 * i - 6:2 * i + 2 - 6])
    plt.grid()
    plt.plot(Dates,dflog.iloc[:,i], label = df2.columns[i])
    plt.ylim(-3*sigmaQ[i]*np.sqrt(T),3*sigmaQ[i]*np.sqrt(T))
    plt.plot(Dates,quantile(sigmaQ[i],time),color='black')
    plt.plot(Dates,quantile(-sigmaQ[i],time),color='black')
    plt.plot(Dates,medium(sigmaQ[i],time),color='red')
    plt.plot(Dates,medium(-sigmaQ[i],time),color='red')
    plt.legend()

for i in range(7, 10):
    ax = plt.subplot(gs[2, 2 * i - 13:2 * i + 2 - 13])
    plt.grid()
    plt.plot(Dates,dflog.iloc[:,i], label = df2.columns[i])
    plt.ylim(-3*sigmaQ[i]*np.sqrt(T),3*sigmaQ[i]*np.sqrt(T))
    plt.plot(Dates,quantile(sigmaQ[i],time),color='black')
    plt.plot(Dates,quantile(-sigmaQ[i],time),color='black')
    plt.plot(Dates,medium(sigmaQ[i],time),color='red')
    plt.plot(Dates,medium(-sigmaQ[i],time),color='red')
    plt.legend()

for i in range(10, 14):
    ax = plt.subplot(gs[3, 2 * i - 20:2 * i + 2 - 20])
    plt.grid()
    plt.plot(Dates,dflog.iloc[:,i], label = df2.columns[i])
    plt.ylim(-3*sigmaQ[i]*np.sqrt(T),3*sigmaQ[i]*np.sqrt(T))
    plt.plot(Dates,quantile(sigmaQ[i],time),color='black')
    plt.plot(Dates,quantile(-sigmaQ[i],time),color='black')
    plt.plot(Dates,medium(sigmaQ[i],time),color='red')
    plt.plot(Dates,medium(-sigmaQ[i],time),color='red')
    plt.legend()


for i in range(14, 17):
    ax = plt.subplot(gs[4, 2 * i - 27:2 * i + 2 - 27])
    plt.grid()
    plt.plot(Dates,dflog.iloc[:,i], label = df2.columns[i])
    plt.ylim(-3*sigmaQ[i]*np.sqrt(T),3*sigmaQ[i]*np.sqrt(T))
    plt.plot(Dates,quantile(sigmaQ[i],time),color='black')
    plt.plot(Dates,quantile(-sigmaQ[i],time),color='black')
    plt.plot(Dates,medium(sigmaQ[i],time),color='red')
    plt.plot(Dates,medium(-sigmaQ[i],time),color='red')
    plt.legend()

plt.tight_layout()

from scipy.stats import multivariate_normal

def MY(SigmaQ,SigmaP,X,T,t):
    s1 = np.array(SigmaQ)
    s2 = np.array(SigmaP)*t/T+np.array(SigmaQ)*(1-t/T)
    if t > 0:
        PY = multivariate_normal.pdf(X,np.zeros(s1.shape[0]),s1*t)
        PM = multivariate_normal.pdf(X,np.diag(s1)*t/2,s2*t)
        return PM/PY
    else:
        return 1

# weights in foreign currency is used as corresponding hedge

def weights(SigmaQ,SigmaP,X,T,t):
    s1 = np.array(SigmaQ)*t
    s2 = (np.array(SigmaP)*t/T+np.array(SigmaQ)*(1-t/T))*t
    if t > 0:
        res = np.linalg.inv(s2).dot(np.diag(s1))/2 +(np.linalg.inv(s1)-np.linalg.inv(s2)).dot(X)
    else:
        s1 = np.array(SigmaQ)
        res = np.linalg.inv(s1).dot(np.diag(s1))/2
    return res

currency_pairs = [["AUD","CAD"],["AUD","JPY"],["AUD","NZD"],["AUD","NOK"],["AUD","GBP"],["AUD","SEK"],["AUD","CHF"],["AUD","USD"],
["CAD","JPY"],["CAD","NZD"],["CAD","NOK"],["CAD","GBP"],["CAD","SEK"],["CAD","CHF"],["CAD","USD"],
["JPY","NZD"],["JPY","NOK"],["JPY","GBP"],["JPY","SEK"],["JPY","CHF"],["JPY","USD"],
["NZD","NOK"],["NZD","GBP"],["NZD","SEK"],["NZD","CHF"],["NZD","USD"],
["NOK","GBP"],["NOK","SEK"],["NOK","CHF"],["NOK","USD"],
["GBP","SEK"],["GBP","CHF"],["GBP","USD"],
["SEK","CHF"],["SEK","USD"],
["CHF","USD"]]

M3 = np.empty(len(time))

scaling = 0.8

for pair in currency_pairs:
  print(pair)
  s1 = covmatrix.loc[pair,pair]
  for i in range(len(time)):
    # print(dfbrown[pair].iloc[i])
    M3[i] = MY(s1,scaling**2*s1,dfbrown[pair].iloc[i],T,time[i])

  M3_1 = M3*df1[pair[0]]/df1[pair[0]].iloc[0]
  M3_2 = M3*df1[pair[1]]/df1[pair[1]].iloc[0]
  M3I = M3/3 + M3_1/3 + M3_2/3

  sharpeM3 = sharpe(pd.Series(M3))
  sharpeM3_1 = sharpe(pd.Series(M3_1))
  sharpeM3_2 = sharpe(pd.Series(M3_2))
  sharpeM3I = sharpe(pd.Series(M3I))
  print(f"Sharpe EUR {sharpeM3} \n Sharpe {pair[0]} {sharpeM3_1} \n Sharpe {pair[1]} {sharpeM3_2} \n Sharpe Index {sharpeM3I}")

  mdM3 = max_drawdown(pd.Series(M3))
  mdM3_1 = max_drawdown(pd.Series(M3_1))
  mdM3_2 = max_drawdown(pd.Series(M3_2))
  mdM3_2 = max_drawdown(pd.Series(M3I))
  print(f"Max drawdown EUR {mdM3} \n Max drawdown {pair[0]} {mdM3_1} \n Max drawdown {pair[1]} {mdM3_2} \n Max drawdown Index {mdM3_2}")

  plt.figure()
  plt.plot(Dates, M3, label="EUR")
  plt.plot(Dates, M3_1, label=pair[0])
  plt.plot(Dates, M3_2, label=pair[1])
  plt.plot(Dates, M3I, label="Index")
  plt.legend()
  plt.grid()
  plt.show()

P3 = np.empty(sampling_points+1)
for pair in currency_pairs:
  print(pair)
  s1 = covmatrix.loc[pair,pair]
  H3 = pd.DataFrame(columns = [pair[0],pair[1]], index = dfbrown.index)
  for i in range(len(time)):
    H3.iloc[i] = weights(s1,scaling**2*s1,dfbrown[[pair[0],pair[1]]].iloc[i],T,time[i])
  plt.figure()
  plt.plot(Dates, 1 - pd.DataFrame.sum(H3, axis = 1), label="EUR")
  plt.plot(Dates, H3.iloc[:,0], label=pair[0])
  plt.plot(Dates, H3.iloc[:,1], label=pair[1])
  plt.legend()
  plt.grid()
  plt.show()
  print(f"\n")
  P3[0] = 1
  for i in range(sampling_points):
    P3[i+1] =  P3[i] + H3.iloc[i,:].dot(simplereturns[[pair[0],pair[1]]].iloc[i+1])*P3[i]
  plt.figure()
  plt.plot(Dates, M3, label="EUR")
  plt.plot(Dates, P3, label="Replication")
  plt.legend()
  plt.grid()
  plt.show()
  print(f"\n")

# from itertools import combinations

# currencies = ['AUD', 'CAD', 'CHF', 'CZK', 'DKK', 'GBP', 'HKD', 'HUF', 'JPY', 'KRW', 'NOK', 'NZD', 'PLN', 'SEK', 'SGD', 'USD', 'ZAR']

# # Generate all possible pairs
# currency_pairs = list(combinations(currencies, 2))

# # Convert tuples to sets to remove duplicates
# unique_currency_pairs = list(set(tuple(sorted(pair)) for pair in currency_pairs))

# # Convert sets back to lists
# unique_currency_pairs = [list(pair) for pair in unique_currency_pairs]

# print(len(unique_currency_pairs))